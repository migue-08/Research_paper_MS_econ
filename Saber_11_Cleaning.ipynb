{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9beaab-f86b-48aa-acca-47788a8afd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "np.set_printoptions(precision=4)\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_colwidth = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d42ca-5f2d-4745-9f25-84f5c58fbacd",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9039d930-78f3-4f2f-8e93-75a7dd75159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we load data with 'pandas.read_csv'\n",
    "\n",
    "data = pd.read_csv(\"saber11_2019_2022.csv\",\n",
    "                   delimiter=\",\",\n",
    "                   on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce7f45e-1276-4d27-807d-c45618ec1ce9",
   "metadata": {},
   "source": [
    "## Dropping unrequired variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7562e780-114a-4cee-b18d-e03e59435952",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['ESTU_TIPODOCUMENTO', 'ESTU_CONSECUTIVO',\n",
    "                          'COLE_CALENDARIO', 'COLE_CARACTER',\n",
    "                          'COLE_COD_DEPTO_UBICACION', 'COLE_COD_MCPIO_UBICACION',\n",
    "                          'COLE_DEPTO_UBICACION', 'COLE_GENERO',\n",
    "                          'COLE_JORNADA', 'COLE_MCPIO_UBICACION',\n",
    "                          'COLE_NOMBRE_ESTABLECIMIENTO', 'COLE_NOMBRE_SEDE',\n",
    "                          'COLE_SEDE_PRINCIPAL', 'ESTU_COD_DEPTO_PRESENTACION',\n",
    "                          'ESTU_COD_MCPIO_PRESENTACION', 'ESTU_DEPTO_PRESENTACION',\n",
    "                          'ESTU_DEPTO_RESIDE', 'ESTU_ESTUDIANTE',\n",
    "                          'ESTU_MCPIO_PRESENTACION', 'ESTU_MCPIO_RESIDE',\n",
    "                          'ESTU_NACIONALIDAD', 'ESTU_PAIS_RESIDE',\n",
    "                          'ESTU_PRIVADO_LIBERTAD', 'FAMI_CUARTOSHOGAR',\n",
    "                          'FAMI_ESTRATOVIVIENDA', 'FAMI_PERSONASHOGAR',\n",
    "                          'DESEMP_INGLES', 'COLE_COD_DANE_ESTABLECIMIENTO',\n",
    "                          'COLE_CODIGO_ICFES', 'ESTU_COD_RESIDE_DEPTO',\n",
    "                          'ESTU_COD_RESIDE_MCPIO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22cd2ec-fe28-4be2-84bb-93370b2f7352",
   "metadata": {},
   "source": [
    "## Removing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32a4018-9934-4593-86a1-e3697f93e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The criteria here is to remove any observation if there is a missing value in any column. To do this, we replace null vallues (' ') with 'np.nans':\n",
    "\n",
    "data = data.replace(' ', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304ef9e4-105a-471e-a036-1c8c00e2e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we drop any row containing a missing value (i.e. 'np.nan')\n",
    "\n",
    "data = data.dropna(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578fb789-608d-4884-b525-4f79838f8e34",
   "metadata": {},
   "source": [
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0fab652-6659-4223-b1da-d0d262aad7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we remove the duplicated data:\n",
    "\n",
    "data = data.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b92aa-9022-43ea-9c09-48aa5babf267",
   "metadata": {},
   "source": [
    "## Research filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de753d8e-7e71-4fdb-9d92-f2a330a1a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some students don't have checking identifications. So I decided to keep only students with information available for research:\n",
    "\n",
    "data = ((data[data['ESTU_ESTADOINVESTIGACION'] == 'PUBLICAR'])\n",
    "        .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147d26f8-c7e4-41e4-8780-6bde9caf0c7d",
   "metadata": {},
   "source": [
    "## Dtype Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02c2229-f7f4-4fc6-a9a8-daf14907c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we transform the variable types to 'float' type\n",
    "\n",
    "data = data.astype({'PUNT_MATEMATICAS': 'float64',\n",
    "                    'PUNT_SOCIALES_CIUDADANAS': 'float64',\n",
    "                    'PUNT_C_NATURALES': 'float64',\n",
    "                    'PUNT_LECTURA_CRITICA': 'float64',\n",
    "                    'PUNT_GLOBAL': 'float64'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd65bf0-2bd0-4a31-8229-8d4cd60b418c",
   "metadata": {},
   "source": [
    "## Estimating and filtering student's age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105d7e4f-5799-4f83-a046-b894503c45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to compute the age of students at the time of taking the test.\n",
    "# First we parse the 'Date of birth' to a 'Datetime' object:\n",
    "\n",
    "data['ESTU_FECHANACIMIENTO'] = pd.to_datetime(data['ESTU_FECHANACIMIENTO'],\n",
    "                                              errors='coerce',\n",
    "                                              dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82d12005-4188-484c-a305-d9f71e68a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_7108\\2603830925.py:3: FutureWarning: Constructing PeriodIndex from fields is deprecated. Use PeriodIndex.from_fields instead.\n",
      "  index = pd.PeriodIndex(year=data['ANO'],\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2019Q4', '2019Q4', '2019Q4', '2019Q4', '2019Q4', '2019Q4',\n",
       "             '2019Q4', '2019Q4', '2019Q4', '2019Q4',\n",
       "             ...\n",
       "             '2022Q1', '2022Q1', '2022Q1', '2022Q1', '2022Q1', '2022Q1',\n",
       "             '2022Q1', '2022Q1', '2022Q1', '2022Q1'],\n",
       "            dtype='period[Q-DEC]', length=845250)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we create PeriodIndex from the year and quarter:\n",
    "\n",
    "index = pd.PeriodIndex(year=data['ANO'],\n",
    "                       quarter=data['PER'],\n",
    "                       freq='Q-DEC')\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b78c6d55-1ae0-4008-8336-c85978d12ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-10-01', '2019-10-01', '2019-10-01', '2019-10-01',\n",
       "               '2019-10-01', '2019-10-01', '2019-10-01', '2019-10-01',\n",
       "               '2019-10-01', '2019-10-01',\n",
       "               ...\n",
       "               '2022-01-01', '2022-01-01', '2022-01-01', '2022-01-01',\n",
       "               '2022-01-01', '2022-01-01', '2022-01-01', '2022-01-01',\n",
       "               '2022-01-01', '2022-01-01'],\n",
       "              dtype='datetime64[ns]', length=845250, freq=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we transform the index to a DatetimeIndex object:\n",
    "\n",
    "index = index.to_timestamp(how='start')\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8777c26-088d-44f2-92da-b3838fa1fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can merge this object into the DataFrame:\n",
    "\n",
    "data['ESTU_FECHAPRESENTACION'] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ba92f77-4e4e-46ed-a79d-05cfc327a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we estimate the age (in days) of students by substracting 'Date of birth' from 'Date of presentation of test', and dividing by 365 days:\n",
    "# And then, we round the age to float number:\n",
    "\n",
    "data['EDAD'] = np.floor((data['ESTU_FECHAPRESENTACION'] - data['ESTU_FECHANACIMIENTO']).dt.days / 365.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc2c41a5-0a7e-4828-b3b0-4e09cbd2362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we filter the age from 14-25 years:\n",
    "\n",
    "age = range(14, 26)\n",
    "\n",
    "data = (data[data['EDAD'].isin(age)]\n",
    "        .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9eaab-4c9a-4dc1-9705-9fc1bf4946d9",
   "metadata": {},
   "source": [
    "## Dropping unrequired variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954d042b-5ce8-42ee-b2ff-8d3a7d64ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['PER', 'ESTU_ESTADOINVESTIGACION',\n",
    "                          'ESTU_FECHANACIMIENTO', 'ESTU_FECHAPRESENTACION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721114b-6ec2-4be0-9f4d-303ad464dd22",
   "metadata": {},
   "source": [
    "## Replacing strings to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab0ccd6e-cd9a-4675-81a4-dafaf22a16ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_7108\\3393196324.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data = data.replace({'N': 0.0, 'S': 1.0,\n"
     ]
    }
   ],
   "source": [
    "# Binary bilingual institution\n",
    "# map1 = {'N': 0, 'S': 1}\n",
    "\n",
    "# Yes/Not family questions\n",
    "# map2 = {'No': 0, 'Si': 1}\n",
    "\n",
    "# Now we can replace the values from the dictionary in the dataframe:\n",
    "\n",
    "data = data.replace({'N': 0.0, 'S': 1.0,\n",
    "                     'No': 0.0, 'Si': 1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34235d80-e3f9-4609-8ea5-312484df23e7",
   "metadata": {},
   "source": [
    "## Mapping and estimating the parents' education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8711ca65-e104-43a2-b0a5-0044cdc6f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea is to estimate the mother’s and father’s years of schooling. But first we are filtering out 'No sabe' and 'No Aplica':\n",
    "\n",
    "names = ['No sabe', 'No Aplica']\n",
    "\n",
    "# Filtering out in mother's education:\n",
    "\n",
    "data = (data[~data['FAMI_EDUCACIONMADRE'].isin(names)]\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "# Filtering out in father's education:\n",
    "\n",
    "data = (data[~data['FAMI_EDUCACIONPADRE'].isin(names)]\n",
    "        .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e0db7a5-a089-4ee2-958d-82d840c1b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we estimate the remaining categories as year of education:\n",
    "\n",
    "education = {'Secundaria (Bachillerato) completa': 14.0,\n",
    "             'Primaria incompleta': 6.0,\n",
    "             'Secundaria (Bachillerato) incompleta': 11.0,\n",
    "             'Educación profesional completa': 19.0,\n",
    "             'Primaria completa': 8.0,\n",
    "             'Técnica o tecnológica completa': 16.0,\n",
    "             'Ninguno': 0.0,\n",
    "             'Postgrado': 22.0,\n",
    "             'Técnica o tecnológica incompleta': 15.0,\n",
    "             'Educación profesional incompleta': 17.0}\n",
    "\n",
    "data['FAMI_EDUCACIONMADRE'] = data['FAMI_EDUCACIONMADRE'].map(education)\n",
    "\n",
    "data['FAMI_EDUCACIONPADRE'] = data['FAMI_EDUCACIONPADRE'].map(education)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8d384-1013-400f-9b3d-2e63bf160de4",
   "metadata": {},
   "source": [
    "## Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "459ea93e-3df8-4e99-93c5-c297042a01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create the dummy/binary variables for 'Ubicación', 'Cole_Naturaleza', and 'Género':\n",
    "\n",
    "# Since this is a difference-in-differences model, we are generating the time dummy variable (2019 and 2022),\n",
    "# and treatment variable ('Fami_tienecomputador_x_Fami_tieneinternet'), and the interaction of the variables:\n",
    "# i.e. ('2022_x_fami_tienecomputador_x_tieneinternet')\n",
    "\n",
    "names2 = ['COLE_AREA_UBICACION', 'COLE_NATURALEZA', 'ESTU_GENERO']\n",
    "\n",
    "dummies = pd.get_dummies(data=data[names2],\n",
    "                         dtype=float)\n",
    "\n",
    "dummies2 = pd.get_dummies(data=data['ANO'],\n",
    "                          prefix='ANO',\n",
    "                          dtype=float)\n",
    "\n",
    "data_with_dummies = (data.drop(columns=names2)\n",
    "                     .join(dummies)\n",
    "                     .join(dummies2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df4711-f3e0-4928-b570-2772cc866c72",
   "metadata": {},
   "source": [
    "## Exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbec8a16-24e4-4114-8934-de1ca54fe7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_with_dummies.to_csv(\"saber11_2019_2022_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e4c29-ce24-4bcd-8eae-0221bc0ff18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
